---
title: "SNP Data Processing and Visualization"
author: "Your Name"
date: "r Sys.Date()"
output: html_document
---

```{r}

library(data.table)
library(ggplot2)
```

# 1. Data Filtering

This section defines several functions to handle and filter SNP data files based on allele frequencies, and process them for further analysis.

#### `target_frequency_filter()`

This function reads an SNP data file and filters the data based on the allele frequency. SNPs are kept if their frequency is between 0.10 and 0.90. It is a restrictive threshold but just that part of the script would be modified if needed.

Very low MAFs are none of our interest as they represent a very little subset of individuals within the whole data of our cohort and therefore BETA values do not represent any biological significance.

```{r}

# Function to read and filter a file
target_frequency_filter <- function(file) {
  # Read file
  data <- fread(file)
  
  # Determine which allele frequency column to use
  freq_col <- if ("AF_coded" %in% colnames(data)) {
    "AF_coded"
  } else if ("EAF" %in% colnames(data)) {
    "EAF"
  } else {
    warning(paste("AF_coded or EAF not found in:", file))
    return(NULL)  # Return NULL if no valid column is found
  }
  
  # Filter SNPs (keep only those with frequency between 0.10 and 0.90)
  data_filtered <- data[(get(freq_col) >= 0.10) & (get(freq_col) <= 0.90)]
  
  return(data_filtered)
}

# Function to extract cohort name from file name
extract_cohort_name <- function(file) {
  gsub("_auto_cleaned.csv.gz", "", basename(file))
}

# Function to process and save files
dataset_processing <- function(files) {
  for (file in files) {
    data_filtered <- target_frequency_filter(file)
    
    if (!is.null(data_filtered)) {
      cohort_name <- extract_cohort_name(file)
      output_file <- paste0("./PROJECTE-PT/datasets_filtered/", cohort_name, "_filtered.csv.gz")
      fwrite(data_filtered, output_file, compress = "gzip")
      print(paste("Filtered file saved:", output_file))
    }
  }
}
```

# 2.Visualization

We want to represent the different BETA values in a BoxPlot to detect significant differences in the median of the values. Cohorts with significant differences in the median of the values must have undergone through a different protocol or the BETA values are suggested to a different extraction process.

![](PROJECTE-PT/easyQC2/EasyQC_PT.SEN-PLOT.png){width="533"}

The SE-N plot obtained in the EasyQC shows the dispersion of several cohort data with respect to ideality. These cohorts are GAIT, LBC1921, LURIC and MARTHA. (two significant points above and under the regression)

This section describes the process of loading filtered SNP data, generating a boxplot to visualize the distribution of the `BETA` values across different cohorts, and saving the plot.

#### `load_filtered_data()`

This function loads and combines filtered data files. It checks if the `BETA` column exists in each file, and if so, extracts the cohort name and appends the relevant `BETA` values along with the cohort information. The result is a single dataset containing `Cohort` and `BETA` for all files.

```{r}

# Function to load filtered data
load_filtered_data <- function(files) {
  data_list <- list()
  
  for (file in files) {
    data <- fread(file)
    
    if ("BETA" %in% colnames(data)) {
      cohort_name <- extract_cohort_name(file)
      data[, Cohort := cohort_name]
      data_list[[length(data_list) + 1]] <- data[, .(Cohort, BETA)]
    } else {
      warning(paste("BETA column missing in file:", file))
    }
  }
  
  return(rbindlist(data_list))
}

# Function to generate Boxplot
plot_beta_distribution <- function(data) {
  ggplot(data, aes(x = Cohort, y = BETA, fill = Cohort)) +
    geom_boxplot(outlier.shape = NA, alpha = 0.7) +  # Clean boxplot
    geom_jitter(width = 0.2, alpha = 0.3) +  # Add points with transparency
    labs(title = "BETA Distribution by Cohort",
         x = "Cohort", y = "BETA") +
    theme_classic() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate labels
}
```

# 3. Full pipeline run

```{r}

# List of original files
files <- c(
  "./PROJECTE-PT/datasets_cleaned/Non_EVT/CHRIS_auto_cleaned.csv.gz",
  "./PROJECTE-PT/datasets_cleaned/Non_EVT/GAIT_auto_cleaned.csv.gz",
  "./PROJECTE-PT/datasets_cleaned/Non_EVT/LURIC_auto_cleaned.csv.gz",
  "./PROJECTE-PT/datasets_cleaned/Non_EVT/RETROVE_CASES_auto_cleaned.csv.gz",
  "./PROJECTE-PT/datasets_cleaned/Non_EVT/RETROVE_CONTROLS_auto_cleaned.csv.gz",
  "./PROJECTE-PT/datasets_cleaned/Non_EVT/SHIP_START_auto_cleaned.csv.gz",
  "./PROJECTE-PT/datasets_cleaned/Non_EVT/SHIP-TREND_Batch1_auto_cleaned.csv.gz",
  "./PROJECTE-PT/datasets_cleaned/Non_EVT/SHIP-TREND_Batch2_auto_cleaned.csv.gz",
  "./PROJECTE-PT/datasets_cleaned/Non_EVT/BioMe_EUR_auto_cleaned.csv.gz",
  "./PROJECTE-PT/datasets_cleaned/Non_EVT/LBC1921_auto_cleaned.csv.gz",
  "./PROJECTE-PT/datasets_cleaned/Non_EVT/LBC1936_auto_cleaned.csv.gz",
  "./PROJECTE-PT/datasets_cleaned/EVT/MARTHA_auto_cleaned.csv.gz"
)

# Execute dataset processing (this will filter and save the data)
dataset_processing(files)

# Directory where filtered files are stored
filtered_dir <- "./PROJECTE-PT/datasets_filtered/"

# List filtered files
filtered_files <- list.files(path = filtered_dir, pattern = "*_filtered.csv.gz", full.names = TRUE)

# Load filtered data
final_data <- load_filtered_data(filtered_files)

# Generate Boxplot
p <- plot_beta_distribution(final_data)

# Save and Show Plot
ggsave("boxplot_betas_cohorts.png", plot = p, width = 10, height = 6, dpi = 150)

```

# 4. Median zoom up

If the previous BoxPlot representing the full distribution of the BETA values in each of the cohorts doesn't provide big insights into the median differences due to the axis values determined by the outliers, a barplot representing the medians of each of the cohorts could be plotted.

```{r}

setDT(final_data)
# Calculate the median of BETA by cohort
median_data <- final_data[, .(median_BETA = median(BETA, na.rm = TRUE)), by = Cohort]

# Create the plot with medians
p_median <- ggplot(median_data, aes(x = Cohort, y = median_BETA, fill = Cohort)) +
  geom_bar(stat = "identity", alpha = 0.7) +  # Bars to show the median
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +  # Reference line at 0
  labs(title = "BETA Median for Cohort",
       x = "Cohort", y = "BETA Median") +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate X axis labels

# Save and display the plot
ggsave("median_betas_cohorts.png", plot = p_median, width = 10, height = 6, dpi = 150)
print(p_median)

```

# 5. Data normalization

As we didn't spot any significant difference in the median of the BETA values, we decide to normalize the values. During the data extraction two different protocols were followed, where some BETA values got transformed and some others not. The transformation consisted on applying a multiplication of the BETA values and the standard error of the mean values. This transformation must be reverted and is the responsible for the existence of further points with respect to ideality in the SE-N plot performed in the EasyQC analysis.

![](PROJECTE-PT/easyQC6/EasyQC_PT.SEN-PLOT.png)

After performing the first normalization and introducing new cohorts, we found all normalized cohorts with exception of GAIT2 found ideality. Further research must be performed on GAIT to determine this behaviour. Now, we see SHIP-TREND_Batch2, whose data was obtained after the first normalization, is separated from ideality.

```{r}

# Define working directories
filtered_dir <- "./PROJECTE-PT/datasets_filtered/"
transformed_dir <- "./PROJECTE-PT/datasets_transformed/"
summary_stats_file <- "./summary_statistics.csv"
cohorts_of_interest <- c("SHIP-TREND_Batch2")

# Function to load and extract SE values
load_se_values <- function(summary_file, cohorts) {
  summary_data <- fread(summary_file)
  se_values <- list()
  
  for (cohort in cohorts) {
    cohort_row <- summary_data[grepl(cohort, summary_data$Cohort), ]
    se_value <- sub(".*\\((.*)\\).*", "\\1", cohort_row$`Untrans mean (SD)`)
    se_values[[cohort]] <- as.numeric(se_value)
  }
  
  return(se_values)
}

# Load SE values
se_values <- load_se_values(summary_stats_file, cohorts_of_interest)

# Function to normalize BETA and SE values
normalize_cohort_data <- function(cohort, filtered_dir, transformed_dir, se_values) {
  filtered_file <- file.path(filtered_dir, paste0(cohort, "_filtered.csv.gz"))
  transformed_file <- file.path(transformed_dir, paste0(cohort, "_transformed.csv.gz"))
  
  if (!file.exists(filtered_file)) {
    warning(paste("File not found:", filtered_file))
    return(NULL)
  }
  
  cohort_data <- fread(filtered_file)
  
  if (!("BETA" %in% colnames(cohort_data) & "SE" %in% colnames(cohort_data))) {
    warning(paste("Missing BETA or SE column in:", filtered_file))
    return(NULL)
  }
  
  cohort_data[, BETA := BETA / se_values[[cohort]]]
  cohort_data[, SE := SE / se_values[[cohort]]]
  
  fwrite(cohort_data, transformed_file, compress = "gzip")
  print(paste("Transformed file saved:", transformed_file))
}

# Apply normalization to each cohort
for (cohort in cohorts_of_interest) {
  normalize_cohort_data(cohort, filtered_dir, transformed_dir, se_values)
}
```
